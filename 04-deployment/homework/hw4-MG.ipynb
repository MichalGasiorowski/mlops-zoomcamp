{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn==1.0.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep scikit-learn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "with open('model.bin', 'rb') as f_in:\n",
    "    dv, lr = pickle.load(f_in)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "categorical = ['PUlocationID', 'DOlocationID']\n",
    "\n",
    "def read_data(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.dropOff_datetime - df.pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df = read_data('https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-02.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def predict(df, dv, lr):\n",
    "    dicts = df[categorical].to_dict(orient='records')\n",
    "    X_val = dv.transform(dicts)\n",
    "    y_pred = lr.predict(X_val)\n",
    "\n",
    "    return y_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q1. Notebook\n",
    "\n",
    "We'll start with the same notebook we ended up with in homework 1.\n",
    "\n",
    "We cleaned it a little bit and kept only the scoring part. Now it's in [homework/starter.ipynb](homework/starter.ipynb).\n",
    "\n",
    "Run this notebook for the February 2021 FVH data.\n",
    "\n",
    "What's the mean predicted duration for this dataset?\n",
    "\n",
    "* 11.19\n",
    "* 16.19\n",
    "* 21.19\n",
    "* 26.19"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean predicted duration = 16.19\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(df, dv, lr)\n",
    "print(f'Mean predicted duration = {y_pred.mean():.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q1 answer :\n",
    "--> B) 16.19"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q2. Preparing the output\n",
    "\n",
    "Like in the course videos, we want to prepare the dataframe with the output.\n",
    "\n",
    "First, let's create an artificial `ride_id` column:\n",
    "\n",
    "```python\n",
    "df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')\n",
    "```\n",
    "\n",
    "Next, write the ride id and the predictions to a dataframe with results.\n",
    "\n",
    "Save it as parquet:\n",
    "\n",
    "```python\n",
    "df_result.to_parquet(\n",
    "    output_file,\n",
    "    engine='pyarrow',\n",
    "    compression=None,\n",
    "    index=False\n",
    ")\n",
    "```\n",
    "\n",
    "What's the size of the output file?\n",
    "\n",
    "* 9M\n",
    "* 19M\n",
    "* 29M\n",
    "* 39M\n",
    "\n",
    "Make sure you use the snippet above for saving the file. It should contain only these two columns. For this question, don't change the\n",
    "dtypes of the columns and use pyarrow, not fastparquet.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "  dispatching_base_num     pickup_datetime    dropOff_datetime PUlocationID  \\\n1      B00021          2021-02-01 00:55:40 2021-02-01 01:06:20          173   \n2      B00021          2021-02-01 00:14:03 2021-02-01 00:28:37          173   \n3      B00021          2021-02-01 00:27:48 2021-02-01 00:35:45           82   \n4               B00037 2021-02-01 00:12:50 2021-02-01 00:26:38           -1   \n5               B00037 2021-02-01 00:00:37 2021-02-01 00:09:35           -1   \n\n  DOlocationID  SR_Flag Affiliated_base_number   duration  \n1           82      NaN        B00021           10.666667  \n2           56      NaN        B00021           14.566667  \n3          129      NaN        B00021            7.950000  \n4          225      NaN                 B00037  13.800000  \n5           61      NaN                 B00037   8.966667  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dispatching_base_num</th>\n      <th>pickup_datetime</th>\n      <th>dropOff_datetime</th>\n      <th>PUlocationID</th>\n      <th>DOlocationID</th>\n      <th>SR_Flag</th>\n      <th>Affiliated_base_number</th>\n      <th>duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>B00021</td>\n      <td>2021-02-01 00:55:40</td>\n      <td>2021-02-01 01:06:20</td>\n      <td>173</td>\n      <td>82</td>\n      <td>NaN</td>\n      <td>B00021</td>\n      <td>10.666667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>B00021</td>\n      <td>2021-02-01 00:14:03</td>\n      <td>2021-02-01 00:28:37</td>\n      <td>173</td>\n      <td>56</td>\n      <td>NaN</td>\n      <td>B00021</td>\n      <td>14.566667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>B00021</td>\n      <td>2021-02-01 00:27:48</td>\n      <td>2021-02-01 00:35:45</td>\n      <td>82</td>\n      <td>129</td>\n      <td>NaN</td>\n      <td>B00021</td>\n      <td>7.950000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>B00037</td>\n      <td>2021-02-01 00:12:50</td>\n      <td>2021-02-01 00:26:38</td>\n      <td>-1</td>\n      <td>225</td>\n      <td>NaN</td>\n      <td>B00037</td>\n      <td>13.800000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>B00037</td>\n      <td>2021-02-01 00:00:37</td>\n      <td>2021-02-01 00:09:35</td>\n      <td>-1</td>\n      <td>61</td>\n      <td>NaN</td>\n      <td>B00037</td>\n      <td>8.966667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # df['ride_id'] = f'{year:04d}/{month:02d}_' + df.index.astype('str')\n",
    "    df_copied = df.copy()\n",
    "    df_copied[\"pickup_yyyy_mm\"] = pd.to_datetime(df_copied['pickup_datetime']).dt.strftime('%Y/%m')\n",
    "    #df_copied[\"ride_id\"] = df_copied[\"pickup_yyyy_mm\"] + \"_\" + df_copied.index.astype('str')\n",
    "    # apply has to be used\n",
    "    df_copied['ride_id'] = df_copied.apply(lambda row: row[\"pickup_yyyy_mm\"] + \"_\" + str(row.name) , axis=1)\n",
    "\n",
    "    return df_copied\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69852/251843148.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_result['y_pred'] = y_pred.tolist()\n"
     ]
    },
    {
     "data": {
      "text/plain": "     ride_id     y_pred\n1  2021/02_1  14.539865\n2  2021/02_2  13.740422\n3  2021/02_3  15.593339\n4  2021/02_4  15.188118\n5  2021/02_5  13.817206",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ride_id</th>\n      <th>y_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2021/02_1</td>\n      <td>14.539865</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2021/02_2</td>\n      <td>13.740422</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2021/02_3</td>\n      <td>15.593339</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2021/02_4</td>\n      <td>15.188118</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2021/02_5</td>\n      <td>13.817206</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copied = preprocess_data(df)\n",
    "\n",
    "df_result = df_copied[['ride_id']]\n",
    "df_result['y_pred'] = y_pred.tolist()\n",
    "\n",
    "df_result.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "df_result.to_parquet(\n",
    "    'df_result.parquet',\n",
    "    engine='pyarrow',\n",
    "    compression=None,\n",
    "    index=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19M\tdf_result.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!du -BM df_result.parquet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What's the size of the output file?\n",
    "\n",
    "* 9M\n",
    "* 19M\n",
    "* 29M\n",
    "* 39M\n",
    "\n",
    "Answer:\n",
    "B) 19M"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q3. Creating the scoring script\n",
    "\n",
    "Now let's turn the notebook into a script.\n",
    "\n",
    "Which command you need to execute for that?\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q4. Virtual environment\n",
    "\n",
    "Now let's put everything into a virtual environment. We'll use pipenv for that.\n",
    "\n",
    "Install all the required libraries. Pay attention to the Scikit-Learn version: check the starter notebook for details.\n",
    "\n",
    "After installing the libraries, pipenv creates two files: Pipfile and Pipfile.lock. The Pipfile.lock file keeps the hashes of the dependencies we use for the virtual env.\n",
    "\n",
    "What's the first hash for the Scikit-Learn dependency?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Answer:\n",
    "08ef968f6b72033c16c479c966bf37ccd49b06ea91b765e1cc27afefe723920b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}