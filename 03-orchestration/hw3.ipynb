{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 3.6 Homework\n",
    "\n",
    "Previous homeworks:\n",
    "\n",
    "**Week 1:**\n",
    "* https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/01-intro/homework.md\n",
    "\n",
    "**Week 2:**\n",
    "* https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/02-experiment-tracking/homework.md\n",
    "\n",
    "The goal of this homework is to familiarize users with workflow orchestration. We start from the solution of homework 1. The notebook can be found below:\n",
    "\n",
    "https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/01-intro/homework.ipynb\n",
    "\n",
    "This has already been converted to a script called `homework.py` in the `03-orchestration` folder of this repo.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "We already have a model training script. Maybe a data scientist in your team handed it to you and your job is schedule the running of training script using a workflow orchestration - Prefect in this case. Below are the requirements. Do not implement them yet, we will do so in this exercise. Just understand the goal.\n",
    "\n",
    "1. The training flow will be run every month.\n",
    "2. The flow will take in a parameter called `date` which will be a datetime.\n",
    "    a. `date` should default to None\n",
    "    b. If `date` is None, set `date` as the current day. Use the data from 2 months back as the training data and the data from the previous month as validation data.\n",
    "    c. If `date` is passed, get 2 months before the `date` as the training data, and the previous month as validation data.\n",
    "    d. As a concrete example, if the date passed is \"2021-03-15\", the training data should be \"fhv_tripdata_2021-01.parquet\" and the validation file will be \"fhv_trip_data_2021-02.parquet\"\n",
    "3. Save the model as \"model-{date}.pkl\" where date is in `YYYY-MM-DD`. Note that `date` here is the value of the flow `parameter`. In practice, this setup makes it very easy to get the latest model to run predictions because you just need to get the most recent one.\n",
    "4. In this example we use a DictVectorizer. That is needed to run future data through our model. Save that as \"dv-{date}.pkl\". Similar to above, if the date is `2021-03-15`, the files output should be `model-2021-03-15.bin` and `dv-2021-03-15.b`.\n",
    "\n",
    "This convention is not strict in industry, and in practice, you will come up with your own system to manage these training pipeline runs. For example, if we wanted to train on the whole history instead of just one month, we'd need to allow for added parameterization and logic in our flow. If the data came in weekly instead of monthly, we might need a different naming convention. But these requirements are already a simple approximation of something you could use in production.\n",
    "\n",
    "On the deployment side, it's very easy to just pull in the latest data and predict it using the latest model and vectorizer files. Tools the MLFlow in the last chapter can simplify that process as well. This homework will focus more on the batch training.\n",
    "\n",
    "In order, this homework assignment will be about:\n",
    "\n",
    "1. Converting the script to a Flow\n",
    "2. Changing the parameters to take in a `date`. Making this parameter dynamic.\n",
    "3. Scheduling a batch training job that outputs the latest model somewhere\n",
    "\n",
    "## Setup\n",
    "\n",
    "You can use either local Prefect Orion or a VM hosted Prefect Orion instance for this. It shouldn't matter. Just note that if you use a VM hosted one, you will need to configure your local API to hit the VM.\n",
    "\n",
    "Video 3.4 of the course will give more detailed instructions if you been run it on a VM."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Get the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-04 23:19:14--  https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-01.parquet\r\n",
      "Resolving nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)... 54.231.192.161\r\n",
      "Connecting to nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)|54.231.192.161|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 11886281 (11M) [binary/octet-stream]\r\n",
      "Saving to: ‘data/fhv_tripdata_2021-01.parquet’\r\n",
      "\r\n",
      "fhv_tripdata_2021-0 100%[===================>]  11.33M  2.75MB/s    in 5.6s    \r\n",
      "\r\n",
      "2022-06-04 23:19:20 (2.04 MB/s) - ‘data/fhv_tripdata_2021-01.parquet’ saved [11886281/11886281]\r\n",
      "\r\n",
      "--2022-06-04 23:19:20--  https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-02.parquet\r\n",
      "Reusing existing connection to nyc-tlc.s3.amazonaws.com:443.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 10645466 (10M) [binary/octet-stream]\r\n",
      "Saving to: ‘data/fhv_tripdata_2021-02.parquet’\r\n",
      "\r\n",
      "fhv_tripdata_2021-0 100%[===================>]  10.15M  5.85MB/s    in 1.7s    \r\n",
      "\r\n",
      "2022-06-04 23:19:22 (5.85 MB/s) - ‘data/fhv_tripdata_2021-02.parquet’ saved [10645466/10645466]\r\n",
      "\r\n",
      "--2022-06-04 23:19:22--  https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-03.parquet\r\n",
      "Reusing existing connection to nyc-tlc.s3.amazonaws.com:443.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 13167110 (13M) [binary/octet-stream]\r\n",
      "Saving to: ‘data/fhv_tripdata_2021-03.parquet’\r\n",
      "\r\n",
      "fhv_tripdata_2021-0 100%[===================>]  12.56M  9.15MB/s    in 1.4s    \r\n",
      "\r\n",
      "2022-06-04 23:19:24 (9.15 MB/s) - ‘data/fhv_tripdata_2021-03.parquet’ saved [13167110/13167110]\r\n",
      "\r\n",
      "FINISHED --2022-06-04 23:19:24--\r\n",
      "Total wall clock time: 10s\r\n",
      "Downloaded: 3 files, 34M in 8.7s (3.92 MB/s)\r\n"
     ]
    }
   ],
   "source": [
    "# use brace expansion to download all January - March files\n",
    "!wget -P data 'https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-0'{1..3}'.parquet'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Q1. Converting the script to a Prefect flow\n",
    "\n",
    "If you want to follow the videos exactly, do:\n",
    "\n",
    "```\n",
    "pip install prefect==2.0b5\n",
    "```\n",
    "\n",
    "If you need Windows support, check `homework-windows.md` for installation instructions.\n",
    "\n",
    "The current script `homework.py` is a fully functional script as long as you already have `fhv_trip_data_2021-01.parquet` and `fhv_trip_data_2021-02.parquet` inside a `data` folder. You should be able to already run it using:\n",
    "\n",
    "```\n",
    "python homework.py\n",
    "```\n",
    "\n",
    "We want to bring this to workflow orchestration to add observability around it. The `main` function will be converted to a `flow` and the other functions will be `tasks`. After adding all of the decorators, there is actually one task that you will need to call `.result()` for inside the `flow` to get it to work. Which task is this?\n",
    "\n",
    "* read_data\n",
    "* prepare_features\n",
    "* train_model\n",
    "* run_model\n",
    "\n",
    "Important: change all `print` statements to use the Prefect logger. Using the `print` statement will not appear in the Prefect UI. You have to call `get_run_logger` at the start of the task to use it.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:51:28.293 | INFO    | prefect.engine - Created flow run 'chirpy-mackerel' for flow 'main'\r\n",
      "20:51:28.293 | INFO    | Flow run 'chirpy-mackerel' - Using task runner 'SequentialTaskRunner'\r\n",
      "20:51:28.300 | WARNING | Flow run 'chirpy-mackerel' - No default storage is configured on the server. Results from this flow run will be stored in a temporary directory in its runtime environment.\r\n",
      "20:51:28.339 | INFO    | Flow run 'chirpy-mackerel' - Created task run 'read_data-4c7f9de4-0' for task 'read_data'\r\n",
      "20:51:30.890 | INFO    | Task run 'read_data-4c7f9de4-0' - Finished in state Completed()\r\n",
      "20:51:30.912 | INFO    | Flow run 'chirpy-mackerel' - Created task run 'prepare_features-4ee39d9f-0' for task 'prepare_features'\r\n",
      "20:51:30.999 | INFO    | Task run 'prepare_features-4ee39d9f-0' - The mean duration of training is 16.2472533682457\r\n",
      "20:51:34.467 | INFO    | Task run 'prepare_features-4ee39d9f-0' - Finished in state Completed()\r\n",
      "20:51:34.513 | INFO    | Flow run 'chirpy-mackerel' - Created task run 'read_data-4c7f9de4-1' for task 'read_data'\r\n",
      "20:51:36.781 | INFO    | Task run 'read_data-4c7f9de4-1' - Finished in state Completed()\r\n",
      "20:51:36.801 | INFO    | Flow run 'chirpy-mackerel' - Created task run 'prepare_features-4ee39d9f-1' for task 'prepare_features'\r\n",
      "20:51:36.883 | INFO    | Task run 'prepare_features-4ee39d9f-1' - The mean duration of training is 16.859265811074096\r\n",
      "20:51:40.047 | INFO    | Task run 'prepare_features-4ee39d9f-1' - Finished in state Completed()\r\n",
      "20:51:40.067 | INFO    | Flow run 'chirpy-mackerel' - Created task run 'train_model-7c866860-0' for task 'train_model'\r\n",
      "20:51:42.560 | INFO    | Task run 'train_model-7c866860-0' - The shape of X_train is (1109826, 525)\r\n",
      "20:51:42.561 | INFO    | Task run 'train_model-7c866860-0' - The DictVectorizer has 525 features\r\n",
      "20:51:47.040 | INFO    | Task run 'train_model-7c866860-0' - The MSE of training is: 10.528519395264997\r\n",
      "20:51:47.138 | INFO    | Task run 'train_model-7c866860-0' - Finished in state Completed()\r\n",
      "20:51:47.156 | INFO    | Flow run 'chirpy-mackerel' - Created task run 'run_model-6559300c-0' for task 'run_model'\r\n",
      "20:51:49.312 | INFO    | Task run 'run_model-6559300c-0' - The MSE of validation is: 11.014287010952778\r\n",
      "20:51:49.377 | INFO    | Task run 'run_model-6559300c-0' - Finished in state Completed()\r\n",
      "20:51:52.523 | INFO    | Flow run 'chirpy-mackerel' - Finished in state Completed('All states completed.')\r\n"
     ]
    }
   ],
   "source": [
    "!python homework.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After adding all of the decorators, there is actually one task that you will need to call `.result()` for inside the `flow` to get it to work. Which task is this?\n",
    "\n",
    "--> train_model\n",
    "since the call to this task is unpacking into lr, dv = ..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Q2. Parameterizing the flow\n",
    "\n",
    "Right now there are two parameters for `main()` called `train_path` and `val_path`. We want to change the flow function to accept `date` instead. `date` should then be passed to a task that gives both the `train_path` and `val_path` to use.\n",
    "\n",
    "It should look like this:\n",
    "\n",
    "```python\n",
    "@flow\n",
    "def main(date=None):\n",
    "    train_path, val_path = get_paths(date).result()\n",
    "    # rest of flow below\n",
    "```\n",
    "\n",
    "Where `get_paths` is a task that you have to implement. The specs for this are outlined in the motivation section. Listing them out again here:\n",
    "\n",
    "The flow will take in a parameter called `date` which will be a datetime.\n",
    "    a. `date` should default to None\n",
    "    b. If `date` is None, use the current day. Use the data from 2 months back as the training data and the data from the previous month as validation data.\n",
    "    c. If a `date` value is supplied, get 2 months before the `date` as the training data, and the previous month as validation data.\n",
    "    d. As a concrete example, if the date passed is \"2021-03-15\", the training data should be \"fhv_tripdata_2021-01.parquet\" and the validation file will be \"fhv_trip_data_2021-02.parquet\"\n",
    "\n",
    "Because we have two files:\n",
    "* fhv_tripdata_2021-01.parquet\n",
    "* fhv_tripdata_2021-02.parquet\n",
    "\n",
    "Change the `main()` flow call to the following:\n",
    "\n",
    "```\n",
    "main(date=\"2021-03-15\")\n",
    "```\n",
    "\n",
    "and it should use those files. This is a simplification for testing our homework.\n",
    "\n",
    "Recall the page from where we downloaded the For-Hire trip data.\n",
    "\n",
    "https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "\n",
    "Download the relevant files needed to run the `main` flow if `date` is 2021-08-15.\n",
    "\n",
    "For example:\n",
    "```\n",
    "main(date=\"2021-08-15\")\n",
    "```\n",
    "\n",
    "By setting up the logger from the previous step, we should see some logs about our training job. What is the validation MSE when running the flow with this date?\n",
    "\n",
    "Note you need to download the relevant files to run. Part of this question is understanding which files the flow should be looking for.\n",
    "\n",
    "The valition MSE is:\n",
    "\n",
    "* 11.637\n",
    "* 11.837\n",
    "* 12.037\n",
    "* 12.237"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing to find a solution for get_paths implementation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/fhv_tripdata_2021-7.parquet']\n",
      "['./data/fhv_tripdata_2021-6.parquet']\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, timedelta, datetime\n",
    "import dateutil.relativedelta\n",
    "\n",
    "\n",
    "date_string = \"2021-08-15\"\n",
    "d = date.fromisoformat(date_string)\n",
    "\n",
    "training_months_dt = [d - dateutil.relativedelta.relativedelta(months=i) for i in range(1, 2)]\n",
    "validation_months_dt = [d - dateutil.relativedelta.relativedelta(months=i) for i in range(2, 3)]\n",
    "\n",
    "training_months_paths = [f'./data/fhv_tripdata_{dt.year}-{dt.month}.parquet' for dt in training_months_dt]\n",
    "validation_months_dt = [f'./data/fhv_tripdata_{dt.year}-{dt.month}.parquet' for dt in validation_months_dt]\n",
    "\n",
    "print(training_months_paths)\n",
    "print(validation_months_dt)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "('./data/fhv_tripdata_2021-02.parquet', './data/fhv_tripdata_2021-01.parquet')"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_paths(date_string=None, months_back_for_training_range=(1, 2), months_back_for_valid_range=(2, 3)):\n",
    "    if date_string is None:\n",
    "        date_string = date.today()\n",
    "\n",
    "    datem = date.fromisoformat(date_string)\n",
    "\n",
    "    training_months_dt = [datem - dateutil.relativedelta.relativedelta(months=i) for i in months_back_for_training_range]\n",
    "    validation_months_dt = [datem - dateutil.relativedelta.relativedelta(months=i) for i in months_back_for_valid_range]\n",
    "\n",
    "    training_months_paths = [f'./data/fhv_tripdata_{dt.year}-{dt.month:02}.parquet' for dt in training_months_dt]\n",
    "    validation_months_paths = [f'./data/fhv_tripdata_{dt.year}-{dt.month:02}.parquet' for dt in validation_months_dt]\n",
    "\n",
    "    return training_months_paths[0], validation_months_paths[0] # return single files for training, since main()  expects it in this format\n",
    "\n",
    "\n",
    "assert(get_paths(\"2021-03-15\") == ('./data/fhv_tripdata_2021-02.parquet', './data/fhv_tripdata_2021-01.parquet'))\n",
    "\n",
    "get_paths(\"2021-03-15\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-06 13:17:29--  https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-06.parquet\r\n",
      "Resolving nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)... 52.216.160.3\r\n",
      "Connecting to nyc-tlc.s3.amazonaws.com (nyc-tlc.s3.amazonaws.com)|52.216.160.3|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 13208079 (13M) [binary/octet-stream]\r\n",
      "Saving to: ‘data/fhv_tripdata_2021-06.parquet’\r\n",
      "\r\n",
      "fhv_tripdata_2021-0 100%[===================>]  12.60M  2.82MB/s    in 13s     \r\n",
      "\r\n",
      "2022-06-06 13:17:43 (1018 KB/s) - ‘data/fhv_tripdata_2021-06.parquet’ saved [13208079/13208079]\r\n",
      "\r\n",
      "--2022-06-06 13:17:43--  https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-07.parquet\r\n",
      "Reusing existing connection to nyc-tlc.s3.amazonaws.com:443.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 12650862 (12M) [binary/octet-stream]\r\n",
      "Saving to: ‘data/fhv_tripdata_2021-07.parquet’\r\n",
      "\r\n",
      "fhv_tripdata_2021-0 100%[===================>]  12.06M  5.40MB/s    in 2.2s    \r\n",
      "\r\n",
      "2022-06-06 13:17:46 (5.40 MB/s) - ‘data/fhv_tripdata_2021-07.parquet’ saved [12650862/12650862]\r\n",
      "\r\n",
      "FINISHED --2022-06-06 13:17:46--\r\n",
      "Total wall clock time: 16s\r\n",
      "Downloaded: 2 files, 25M in 15s (1.65 MB/s)\r\n"
     ]
    }
   ],
   "source": [
    "#Download the relevant files needed to run the `main` flow if `date` is 2021-08-15.\n",
    "\n",
    "!wget -P data 'https://nyc-tlc.s3.amazonaws.com/trip+data/fhv_tripdata_2021-0'{6..7}'.parquet'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13:38:08.129 | INFO    | prefect.engine - Created flow run 'neat-puffin' for flow 'main'\r\n",
      "13:38:08.129 | INFO    | Flow run 'neat-puffin' - Using task runner 'SequentialTaskRunner'\r\n",
      "13:38:08.136 | WARNING | Flow run 'neat-puffin' - No default storage is configured on the server. Results from this flow run will be stored in a temporary directory in its runtime environment.\r\n",
      "13:38:08.171 | INFO    | Flow run 'neat-puffin' - Created task run 'get_paths-6e696e34-0' for task 'get_paths'\r\n",
      "13:38:08.209 | INFO    | Task run 'get_paths-6e696e34-0' - Finished in state Completed()\r\n",
      "13:38:08.210 | INFO    | Flow run 'neat-puffin' - Path for training: ./data/fhv_tripdata_2021-06.parquet, Path for validation: ./data/fhv_tripdata_2021-07.parquet\r\n",
      "13:38:08.230 | INFO    | Flow run 'neat-puffin' - Created task run 'read_data-4c7f9de4-0' for task 'read_data'\r\n",
      "13:38:11.192 | INFO    | Task run 'read_data-4c7f9de4-0' - Finished in state Completed()\r\n",
      "13:38:11.225 | INFO    | Flow run 'neat-puffin' - Created task run 'prepare_features-4ee39d9f-0' for task 'prepare_features'\r\n",
      "13:38:11.327 | INFO    | Task run 'prepare_features-4ee39d9f-0' - The mean duration of training is 18.230538791569113\r\n",
      "13:38:15.316 | INFO    | Task run 'prepare_features-4ee39d9f-0' - Finished in state Completed()\r\n",
      "13:38:15.338 | INFO    | Flow run 'neat-puffin' - Created task run 'read_data-4c7f9de4-1' for task 'read_data'\r\n",
      "13:38:18.200 | INFO    | Task run 'read_data-4c7f9de4-1' - Finished in state Completed()\r\n",
      "13:38:18.220 | INFO    | Flow run 'neat-puffin' - Created task run 'prepare_features-4ee39d9f-1' for task 'prepare_features'\r\n",
      "13:38:18.313 | INFO    | Task run 'prepare_features-4ee39d9f-1' - The mean duration of training is 17.91113046137945\r\n",
      "13:38:22.388 | INFO    | Task run 'prepare_features-4ee39d9f-1' - Finished in state Completed()\r\n",
      "13:38:22.421 | INFO    | Flow run 'neat-puffin' - Created task run 'train_model-7c866860-0' for task 'train_model'\r\n",
      "13:38:25.216 | INFO    | Task run 'train_model-7c866860-0' - The shape of X_train is (1222031, 525)\r\n",
      "13:38:25.216 | INFO    | Task run 'train_model-7c866860-0' - The DictVectorizer has 525 features\r\n",
      "13:38:29.523 | INFO    | Task run 'train_model-7c866860-0' - The MSE of training is: 11.789353538847092\r\n",
      "13:38:29.633 | INFO    | Task run 'train_model-7c866860-0' - Finished in state Completed()\r\n",
      "13:38:29.648 | INFO    | Flow run 'neat-puffin' - Created task run 'run_model-6559300c-0' for task 'run_model'\r\n",
      "13:38:32.315 | INFO    | Task run 'run_model-6559300c-0' - The MSE of validation is: 11.637023826050765\r\n",
      "13:38:32.387 | INFO    | Task run 'run_model-6559300c-0' - Finished in state Completed()\r\n",
      "13:38:36.365 | INFO    | Flow run 'neat-puffin' - Finished in state Completed('All states completed.')\r\n"
     ]
    }
   ],
   "source": [
    "# Run the homework for hw3.Q2\n",
    "# main(date=\"2021-08-15\")\n",
    "!python homework.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The valition MSE is:\n",
    "\n",
    "* 11.637\n",
    "* 11.837\n",
    "* 12.037\n",
    "* 12.237\n",
    "\n",
    "13:38:32.315 | INFO    | Task run 'run_model-6559300c-0' - The MSE of validation is: 11.637023826050765\n",
    "--> A)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}